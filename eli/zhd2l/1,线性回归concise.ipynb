{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 线性回归简洁实现\n",
    "```\n",
    "训练步骤：\n",
    "1、初始化模型参数: w,b\n",
    "2、设置超参数: lr,num_epochs\n",
    "3、前向传播: 计算出y_hat\n",
    "4、计算出loss: （关于y_hat 与 y 的）squared_loss\n",
    "5、反向传播，计算梯度: （参数w、b关于loss函数的梯度）【注意：反向传播之前必须清除上一个 epoch 保存的梯度】\n",
    "6、使用梯度，更新参数: Optimization Algorithm （sgd、Adagrad、Adam等） 【注意：with torch.no_grad():】\n",
    "7、重复步骤3-6，num_epochs次。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:18:21.421909200Z",
     "start_time": "2023-05-28T10:18:21.410349200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "# 设置plt可以显示中文字体，否则会显示乱码\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:18:21.449965400Z",
     "start_time": "2023-05-28T10:18:21.419904Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "生成加入噪声的测试数据\n",
    "生成y=Xw+b+噪声\n",
    "\"\"\"\n",
    "def synthetic_data(w, b, num_examples):\n",
    "    X = torch.normal(0, 1, (num_examples, len(w))) # 高斯分布(正态分布)\n",
    "    # X = torch.rand((num_examples,len(w))) # 均匀分布\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "# 生成测试数据\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "features.shape,labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:18:21.693217300Z",
     "start_time": "2023-05-28T10:18:21.435943600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\"\"\"\n",
    "查看测试数据散点图\n",
    "\"\"\"\n",
    "for i in range(len(true_w)):\n",
    "    plt.scatter(features[:, i], labels)\n",
    "    plt.xlabel(f\"feature-{i+1}\")\n",
    "    plt.ylabel(f\"label\")\n",
    "    plt.title(f\"第{i + 1}个特征features[:, {i}]和labels的散点图(w={true_w[i]})\", fontproperties=font)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:18:21.708732100Z",
     "start_time": "2023-05-28T10:18:21.695215200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "调用框架中现有的API来读取数据\n",
    "构造一个PyTorch数据迭代器\n",
    "\"\"\"\n",
    "def load_array(data_arrays,batch_size,is_train=True):\n",
    "    data_set = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(data_set,batch_size,shuffle=is_train)\n",
    "\n",
    "batch_size = 3\n",
    "data_iter = load_array((features, labels), batch_size)\n",
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:18:21.736792100Z",
     "start_time": "2023-05-28T10:18:21.708732100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "定义模型\n",
    "在PyTorch中，全连接层在Linear类中定义。\n",
    "值得注意的是，我们将两个参数传递到nn.Linear中。\n",
    "第一个指定输入特征形状，即2;\n",
    "第二个指定输出特征形状，输出特征形状为单个标量，因此为1。\n",
    "\"\"\"\n",
    "net = torch.nn.Sequential(torch.nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:18:21.747813900Z",
     "start_time": "2023-05-28T10:18:21.725280500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 初始化模型参数\n",
    "# 深度学习框架通常有预定义的方法来初始化参数。\n",
    "# 在这里，我们指定每个权重参数应该从均值为0、标准差为0.01的正态分布中随机采样， 偏置参数将初始化为零。\n",
    "\"\"\"\n",
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:18:21.757843100Z",
     "start_time": "2023-05-28T10:18:21.741305900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 定义损失函数\n",
    "# 计算均方误差使用的是MSELoss类，也称为平方范数。 默认情况下，它返回所有样本损失的平均值.\n",
    "\"\"\"\n",
    "loss = torch.nn.MSELoss()\n",
    "# loss = nn.SmoothL1Loss(beta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:18:21.791419100Z",
     "start_time": "2023-05-28T10:18:21.756336300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "定义优化算法\n",
    "PyTorch在optim模块中实现了该算法的许多变种。\n",
    "当我们实例化一个SGD实例时，我们要指定优化的参数 （可通过net.parameters()从我们的模型中获得）以及优化算法所需的超参数字典lr。\n",
    "\"\"\"\n",
    "lr = 0.03\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:18:21.925903Z",
     "start_time": "2023-05-28T10:18:21.773878Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 训练\n",
    "\"\"\"\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "data_iter = load_array((features, labels), batch_size=batch_size)\n",
    "# 在使用data_iter函数时，我们需要注意最后一个批量可能比其他批量更小，需要特殊处理。\n",
    "train_all_dataset_loss_list = [] # 用于保存历史loss均值\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        # print(y.shape)\n",
    "        l = loss(net(X) ,y) # 通过调用net(X)生成预测并计算损失l（前向传播）\n",
    "        optimizer.zero_grad() # 反向传播之前必须清除上一个 epoch 保存的梯度\n",
    "        l.backward() # 通过进行反向传播来计算梯度\n",
    "        # print(f\"w 的梯度：{net[0].weight.grad}\") # 查看模型中的权重张量的梯度,需要注意的是，只有在调用 backward() 方法之后，才能查看张量的梯度。\n",
    "        # print(f\"w 变化: {net[0].weight.data} ->\",end='')  # 随机梯度下降算法SGD 优化前的参数值\n",
    "        optimizer.step() # 通过调用优化器来更新模型参数\n",
    "        # print(f\" {net[0].weight.data}\") # 随机梯度下降算法SGD 优化后的参数值w\n",
    "    with torch.no_grad():\n",
    "        l = loss(net(features), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {l:f}')\n",
    "        train_all_dataset_loss_list.append(l.item())\n",
    "\n",
    "w = net[0].weight.data\n",
    "print(f\"w 的真实值: {true_w}, w 的估计值: {w.reshape(true_w.shape)}\")\n",
    "print('w的估计误差：', true_w - w.reshape(true_w.shape))\n",
    "b = net[0].bias.data\n",
    "print(f\"b 的真实值: {true_b}, b 的估计值: {b}\")\n",
    "print('b的估计误差：', true_b - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:18:37.152875500Z",
     "start_time": "2023-05-28T10:18:37.039822Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 画图-训练误差曲线\n",
    "train_all_dataset_loss_list_Y = train_all_dataset_loss_list\n",
    "train_all_dataset_loss_list_X = [i for i in range(len(train_all_dataset_loss_list_Y))]\n",
    "plt.plot(train_all_dataset_loss_list_X, train_all_dataset_loss_list_Y,marker='o')\n",
    "plt.title(\"训练误差曲线\", fontproperties=font)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-28T10:18:22.062801200Z",
     "start_time": "2023-05-28T10:18:22.045597400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
